© 2026 Ji Hua.
This repository documents the Vibe + Coding methodology.
Licensed under CC BY-NC-ND 4.0.

Vibe + Coding — Version 0.2

---

# 第二章 | 从问题到解法：在工程约束下收敛的协作结构

在第一章，我们已经完成了一件关键的事情：

我们不再讨论“AI 能不能写好代码”，
而是将问题重新定位为一个更根本、也更稳定的工程问题——

在 AI 参与软件工程的前提下，一个责任体系如何才能在结构上成立。

如果“决定与责任不可分离”这一工程公理成立，那么问题就不再是“要不要用 AI”，而必然变成：

在什么样的协作结构下使用 AI，工程才能在 1 → 100 的时间尺度上不失控。

这意味着，任何可行解，都必须首先满足一组不可回避的工程约束。

---

## 一、把问题工程化：任何解法都必须回答的三个问题

在任何工程系统中，所谓“责任问题”并不是抽象的道德讨论，而是可以被还原为三个具体、可验证的问题：

- 谁拥有决策权？
- 决策发生在什么阶段？
- 决策失败的后果由谁承担？

如果这三个问题无法被明确回答，那么所谓的“协作流程”“最佳实践”，就只能依赖个人自觉，而无法形成稳定、可复制的工程约束。

传统 AI Coding 的核心问题正是在于此：

这三个问题从未被显式回答，
却在实现过程中被不断隐式解决、反复修改、相互覆盖。

---

## 二、额外工程约束：不是所有“正确”的解法都能成立

到这里为止，我们只是确认了一件事：

高责任决策不能在错误的阶段，由错误的主体发生。

但这一结论本身，并不足以构成一个可用的工程解法。

在真实工程中，一个解法即便在逻辑上正确，只要违背工程现实或人类工作方式，同样无法长期成立。因此，在继续推导之前，我们必须引入一组额外的工程约束，用以限定可行解空间。

这些约束不是理想化目标，而是任何可落地方案都必须同时满足的前提条件。

---

### 约束一：AI 必须被引入

我们讨论的不是回退到传统开发方式。

解法必须以内建 AI 协作为前提，而不是通过不使用 AI 来规避问题。
任何要求工程师重新承担全部实现、分析与执行工作的方案，都不在讨论范围之内。

---

### 约束二：人类必须轻松

解法不能通过将心智负担重新压回人类工程师身上来换取稳定性。

如果一个方案要求工程师长期处于高度形式化、重流程、重文书的工作状态，那么它在现实中同样不可持续。

换言之，工程稳定性不能以牺牲工程师的便利性为代价。
如果引入这一解法不能显著降低工程师在实现阶段的心智负担，那么这个解法本身就不成立。

---

### 约束三：重要决策必须由人类完成

所有可能导致长期结构性后果的高责任判断，只能由承担后果的人类工程师完成。

任何 AI 都不应被允许在不受约束的情况下做出此类判断。

---

### 约束四：AI 被允许做决策，但不能推翻人类的决策

这个解法不能通过禁止 AI 决策来获得安全性。

AI 应当被允许在低责任空间内做出大量决策，以解放人类工程师；
但与此同时，人类工程师已经做出的决策不得被 AI 的后续行为所影响、修改或隐式推翻。

---

### 约束五：AI 的决策风险必须可控

AI 在执行过程中所拥有的决策自由，必须被明确限定在一个可审计、可回溯的范围之内。

任何无法界定其裁量边界、无法判断其是否越权的决策行为，都是不可接受的。

---

### 约束六：解法必须与问题域无关

这一协作结构不应只适用于某一类特定问题域或技术类型。

只要一个问题中存在需要被承担长期后果的判断，该结构就应当能够被应用。

是否启用这一解法，由人类工程师根据问题性质自行判断；
但一旦启用，其责任划分、决策冻结与授权审计的逻辑，不应随问题域、技术栈或实现形式发生变化。

---

## 三、从约束到解决方案

在上述约束下，我们可以逐步收敛可行解空间。

首先，任何没有 AI 参与的编程方式都被直接排除。

其次，根据约束四，即 AI 的决策不能反向影响人类工程师的决策，我们可以发现，这一要求在结构上与软件工程中的依赖倒置原则一致：

高层决策不能依赖底层实现，
而必须通过稳定接口进行隔离，双方共同依赖该接口。

在这里，这个接口不能是代码，也不能是对话状态，而只能是一个显式、可冻结、可审计的工程产物。

---

### 决策接口的外显化

一个自然且必要的选择是：

将人类工程师做出的关键决策外显为文档，并将该文档作为人类与 AI 之间的唯一决策接口。
对话天然是低熵的、弥散的。在漫长的对话中，早期的工程约束往往会被后期的实现细节所淹没。
外显化文档的本质是‘决策冷冻’——通过将流动的对话固化为静态的文档，我们人为地制造了一个熵减的过程，确保系统的演化路径始终锚定在初始的工程设计之上。
通过文档来杜绝Coding Agent接触到决策上下文的可能，防止讨论过程中的噪音污染Coding Agent。


在工程上，这里的文档并非单一形态，而是具有明确层级关系的两类约束载体：

一、设计文档（Design Document）
用于约束人类工程师自身，回答的是：
我想要什么，以及我不允许发生什么。

该文档承载所有高责任判断与长期结构性决策，是人类工程师对系统未来所做出的承诺。

二、任务说明书（Task Specification）
用于约束 Coding Agent，回答的是：
你该干什么，以及你绝不能干什么。

该文档从设计文档中派生而来，是对执行行为的具体授权。

在这两类文档之间，存在明确且不可逆的效力层级关系：

设计文档的效力高于任务说明书。

- 任务说明书只能细化、拆解设计文档中的已冻结决策
- 不得引入新的设计判断
- 不得弱化或修改设计文档中已明确的约束

当二者出现任何不一致时，一律以设计文档为准。

Coding Agent 只能依据任务说明书执行；
任何未被任务说明书明确授权的行为，
即便可以从设计文档中推测得到，
在执行阶段一律视为未授权行为。

通过这一分层结构，人类决策、执行授权与 AI 行为边界被显式区分并永久锁定。

---

### Vibe Writing：在不增加负担的前提下完成决策冻结

在人类工程师参与的阶段，我们仍然允许 AI 作为认知放大器存在。

人类工程师可以通过与 AI 的自然语言讨论来澄清需求、探索方案、比较权衡。
这一过程保持了 Vibe Coding 的轻松性。

但这一阶段的产出不再是代码，而是文档。

这一过程可以被称为 Vibe Writing。

需要强调的是，这里的文档并不是穷尽实现细节的规格说明，
而是人类高责任判断的最小外显集合。

---

### 执行与审计：受限自由下的高效实现

在设计文档冻结之后，Vibe Agent 会将其拆解为一组标准化的任务说明书。

每一份任务说明书必须明确：

- 任务目标
- 任务范围（包含明确的禁止项）
- 允许的裁量空间
- 完成标准与验收条件

Coding Agent 在任务说明书定义的授权空间内执行实现：

- 在范围内拥有自由裁量权
- 对范围之外的内容保持必要的无知
- 达到验收标准后必须停止执行并返回结果

对全局的必要无知是该结构的核心保护机制。
如果 Coding Agent 拥有修改全局的权限，它就会在实现局部功能时，为了‘方便’而破坏全局一致性。任务说明书不仅是授权书，更是隔离墙。

Coding Agent的执行结果将交由一个独立的Audit Agent 进行验证。

Audit Agent 的职责被严格限定为：

- 验证实现是否符合任务说明书
- 判断是否存在越界行为
- 标注差异位置与失败原因

Audit Agent 不得引入新的实现或设计判断，也不得对代码进行修复。

---

### 递归结构与唯一回流路径

当审计失败时，只允许以下回流路径：

- 若任务说明不明确或自相矛盾，回流至设计阶段，由人类工程师修订文档
- 若任务明确但实现失败，回流至 Coding Agent 重新执行

不存在跨层修补或顺便修一下的路径。

整个流程以此方式递归推进。

---

## 四、解法的必然形态

基于以上推导，我们可以得到一种必然的解法形态：

- 人类工程师通过与 AI（Vibe Agent）的讨论完成高责任决策
- 决策被外显为设计文档并被冻结
- 设计文档被拆解为任务说明书，作为唯一执行授权
- AI（Coding Agent）在授权空间内执行实现
- 执行结果通过独立审计验证边界
- 所有失败仅能回流至其所属责任层级

这套解法被称为 Vibe + Coding。

它的核心转变在于：

把 Vibe Coding 变成 Vibe Writing + AI Coding。

- 在 Vibe 阶段，产出的是决策与约束，而不是代码
- 在 Coding 阶段，代码只是任务说明书被执行后的结果

在这一结构中：

- 人类工程师承担高责任判断，并对长期后果负责
- AI 在明确授权的空间内高效执行
- 决策与执行之间不存在反向污染路径

---

## 五、结论

Vibe + Coding 并不是一种更聪明的 AI 使用技巧，
而是一种在既定工程公理与现实约束下，被推导出来的协作结构。

它的目标不是让 AI 更强大，
而是确保：

高级决策永远只由能够承担后果的人做出，
且绝不被低级执行在实现阶段反向塑形。
